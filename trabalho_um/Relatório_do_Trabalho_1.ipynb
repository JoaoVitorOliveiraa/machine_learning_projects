{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1c0KMURNCGr"
   },
   "source": [
    "# Relatório do Trabalho 1 - Introdução ao Aprendizado de Máquina\n",
    "### Aluno: João Vitor dos Santos Oliveira\n",
    "### Professor: Heraldo Almeida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YXpnSjKP4Dj",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 01 - Importação das Bibliotecas Utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E29fv_4yQMjU"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdU0vMRKQTBL",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 02 - Importação dos Conjuntos de Teste e Treinamento\n",
    "\n",
    "- Observação: Salvei os conjuntos em um diretório de nome 'data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "MR6K-vogRZJs",
    "outputId": "72943316-0b4d-41a3-bdd7-50150399b65a"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/conjunto_de_teste.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8a9597fa07f7>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcaminho_conjunto_de_teste\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'conjunto_de_teste.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcaminho_conjunto_de_treinamento\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'conjunto_de_treinamento.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdados_teste\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaminho_conjunto_de_teste\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdados_treinamento\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaminho_conjunto_de_treinamento\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mids_solicitantes_dados_teste\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdados_teste\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id_solicitante'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/conjunto_de_teste.csv'"
     ]
    }
   ],
   "source": [
    "caminho_conjunto_de_teste = Path('../data') / 'conjunto_de_teste.csv'\n",
    "caminho_conjunto_de_treinamento = Path('../data') / 'conjunto_de_treinamento.csv'\n",
    "dados_teste = pd.read_csv(caminho_conjunto_de_teste)\n",
    "dados_treinamento = pd.read_csv(caminho_conjunto_de_treinamento)\n",
    "ids_solicitantes_dados_teste = dados_teste['id_solicitante']\n",
    "dados_teste = dados_teste.iloc[:, 1:]\n",
    "dados_treinamento = dados_treinamento.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0t6XPLv2aHz",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 03 - Análise dos Dados de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "kYw1X4zW2stc",
    "outputId": "71ab5ea3-3e57-4ab2-a470-31bc91d09a50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t-----Dez primeiras linhas do conjunto de treinamento-----\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dados_treinamento' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-dcabbcf7a770>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\t\\t-----Dez primeiras linhas do conjunto de treinamento-----\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdados_treinamento\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# ------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dados_treinamento' is not defined"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "#  Exibição das primeiras 10 linhas do conjunto de treinamento através da função head()\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\t\\t-----Dez primeiras linhas do conjunto de treinamento-----\\n\")\n",
    "print(dados_treinamento.head(n=10))\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#  Descrição dos dados de treinamento (como número de linhas, tipo de cada\n",
    "#  atributo e número de valores não nulos) através da função info()\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Descrição dos dados do conjunto de treinamento-----\\n\")\n",
    "dados_treinamento.info()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#  Descobrindo quais categorias existem nas features e no alvo, além de quantos\n",
    "#  dígitos pertencem a cada categoria, usando a função value_counts()\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Categorias das features e do alvo, com suas respectivas quantidades-----\\n\")\n",
    "for feature in list(dados_treinamento.columns):\n",
    "    print(\"\\n\", dados_treinamento[feature].value_counts())\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#  Resumo dos atributos numéricos do conjunto de treinamento através da\n",
    "#  função describe()\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Resumo dos atributos numéricos-----\\n\")\n",
    "print(dados_treinamento.describe())\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Exibindo as features do dataset e seus tipos\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Features disponíveis-----\\n\")\n",
    "print(list(dados_treinamento.columns))\n",
    "\n",
    "print(\"\\n\\n-----Tipos das features-----\\n\")\n",
    "print(dados_treinamento.dtypes)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Exibindo o histograma entre as quantidades e os valores do alvo\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Histograma do alvo-----\\n\")\n",
    "grafico = dados_treinamento['inadimplente'].plot.hist(bins=30)\n",
    "grafico.set(title='inadimplente', xlabel='Quantidades', ylabel='Valores')\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#  Melhor exibição das classes das features, pois os describe() não exibiu todas\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Melhor exibição das classes das features-----\\n\")\n",
    "for feature in list(dados_treinamento.columns):\n",
    "    print(f\"\\nClasses {feature}: \", list(dados_treinamento[feature].unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ues0Dslb2_oj",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 04 - Remoção de Features Inúteis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1GriYvjP3GCb"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "#  Remoção das features inúteis, notificadas no arquivo 'dicionario_de_dados'\n",
    "#  grau_instrucao: Totalmente preenchida com zeros\n",
    "#  possui_telefone_celular: Totalmente preenchida com \"N\"\n",
    "#  qtde_contas_bancarias_especiais: Conteúdo idêntico à \"qtde_contas_bancarias\"\n",
    "#  meses_no_trabalho: Vasta maioria com valor zero.\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "features_inuteis = [\"grau_instrucao\", \"possui_telefone_celular\", \"qtde_contas_bancarias_especiais\", \"meses_no_trabalho\"]\n",
    "dados_treinamento.drop(features_inuteis, axis=1, inplace=True)\n",
    "dados_teste.drop(features_inuteis, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzTEd8k03KHj",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 05 - Remoção de Features que Possuíam uma Classe Extremamente Dominante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGN2nObLU3Ke"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "#  Remoção de features que possuíam uma classe extremamente dominante\n",
    "#  nacionalidade: Vasta maioria com valor um (1: 19152)\n",
    "#  valor_patrimonio_pessoal: Vasta maioria com valor zero (0: 19072)\n",
    "#  grau_instrucao_companheiro: Vasta maioria com valor zero (0: 19345)\n",
    "#  tipo_endereco: Vasta maioria com valor um (1: 19873)\n",
    "#  possui_cartao_diners: Vasta maioria com valor zero (0: 19968)\n",
    "#  possui_cartao_amex: Vasta maioria com valor zero (0: 19959)\n",
    "#  possui_outros_cartoes: Vasta maioria com valor zero (0: 19955)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "features_classes_dominantes = [\"nacionalidade\", \"valor_patrimonio_pessoal\", \"grau_instrucao_companheiro\", \"tipo_endereco\",\n",
    "                               'possui_cartao_diners', 'possui_cartao_amex', 'possui_outros_cartoes']\n",
    "\n",
    "dados_treinamento.drop(features_classes_dominantes, axis=1, inplace=True)\n",
    "dados_teste.drop(features_classes_dominantes, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5_0XKWtVQZk",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 06 - Criação e Aplicação de uma Função para Substituir o Valor de uma Classe em uma Feature\n",
    "\n",
    "- Foram substituídas as classes 'N' e 'Y' por 0 e 1, nas features 'possui_telefone_residencial', 'vinculo_formal_com_empresa' e 'possui_telefone_trabalho'.\n",
    "- Foram substituídas as classes dos estados brasileiros pelas regiões do Brasil.\n",
    "- Foram cubstituídos os espaços ausentes das features, que estavam incompletas e que o significado de suas classes não foi especificado, pela mediana dos valores de suas classes, pois os valores não estão uniformemente distribuídos.\n",
    "- Na feature 'sexo', os espaços ' ' foram substituídos pela classe 'N' (não informado).\n",
    "- Nas features dos estados brasileiros, os espaços ' ' foram substituídos por 'classe_invalida'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTMKVjtGVTdE"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "#  Criação de uma função para substituir o valor de uma classe em uma feature\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def replace_class_value(data, features, old_value, new_value):\n",
    "    \"Função que substitui o valor de uma classe em uma feature.\"\n",
    "\n",
    "    for feature in features:\n",
    "        data[feature] = data[feature].replace({old_value: new_value})\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#  Aplicação da função de substituir valores de classes\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Substituindo as classes binárias 'N' e 'Y' em 0 e 1 de cada feature categórica que apresenta essas classes.\n",
    "features_com_classes_y_n = ['possui_telefone_residencial', 'vinculo_formal_com_empresa', 'possui_telefone_trabalho']\n",
    "replace_class_value(dados_treinamento, features_com_classes_y_n, 'Y', 1)\n",
    "replace_class_value(dados_treinamento, features_com_classes_y_n, 'N', 0)\n",
    "replace_class_value(dados_teste, features_com_classes_y_n, 'Y', 1)\n",
    "replace_class_value(dados_teste, features_com_classes_y_n, 'N', 0)\n",
    "\n",
    "# Dicionário onde as chaves e valores são as regiões do Brasil e listas com siglas de estados.\n",
    "dict_regioes_do_brasil = {'regiao_norte': ['AC', 'AP', 'AM', 'PA', 'RO', 'RR', 'TO'],\n",
    "                          'regiao_nordeste': ['AL', 'BA', 'CE', 'MA', 'PB', 'PE', 'PI', 'RN', 'SE'],\n",
    "                          'regiao_centro_oeste': ['DF', 'GO', 'MT', 'MS'],\n",
    "                          'regiao_sudeste': ['ES', 'MG', 'RJ', 'SP'],\n",
    "                          'regiao_sul': ['PR', 'RS', 'SC']}\n",
    "\n",
    "# Lista com todas as features que possuem siglas de estados brasileiros como classes.\n",
    "features_siglas_estados_brasileiros = ['estado_onde_trabalha', 'estado_onde_nasceu', 'estado_onde_reside']\n",
    "\n",
    "# Substituindo cada estado por sua respectiva região, em cada feature listada.\n",
    "for regiao, classes in dict_regioes_do_brasil.items():\n",
    "    for classe in classes:\n",
    "        replace_class_value(dados_treinamento, features_siglas_estados_brasileiros, classe, regiao)\n",
    "        replace_class_value(dados_teste, features_siglas_estados_brasileiros, classe, regiao)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#  Substituindo os espaços ausentes das features, que estavam incompletas e que o\n",
    "#  significado de suas classes não foi especificado, pela mediana dos valores de\n",
    "#  suas classes, pois os valores não estão uniformemente distribuídos.\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "features_incompletas = ['tipo_residencia', 'meses_na_residencia', 'profissao', 'ocupacao', 'profissao_companheiro','sexo',\n",
    "                        'codigo_area_telefone_residencial', 'codigo_area_telefone_trabalho',\n",
    "                        'estado_onde_trabalha', 'estado_onde_nasceu', 'estado_onde_reside']\n",
    "\n",
    "for feature in features_incompletas:\n",
    "\n",
    "    # Substituindo espaços ' ' por 'N' (não informado).\n",
    "    if feature == 'sexo':\n",
    "        replace_class_value(dados_treinamento, [feature], ' ', 'N')\n",
    "        replace_class_value(dados_teste, [feature], ' ', 'N')\n",
    "\n",
    "    # Substituindo os espaços ' ' por \"classe_invalida\".\n",
    "    elif feature in features_siglas_estados_brasileiros:\n",
    "        replace_class_value(dados_treinamento, [feature], ' ', 'classe_invalida')\n",
    "        replace_class_value(dados_teste, [feature], ' ', 'classe_invalida')\n",
    "\n",
    "    # Substituindo os espaços ' ' pela média dos valores (após transformá-los em números).\n",
    "    elif feature in ['codigo_area_telefone_residencial', 'codigo_area_telefone_trabalho']:\n",
    "\n",
    "        # Primeiramente, substituímos os espaços vazios por None, a fim de realizar a conversão da coluna.\n",
    "        replace_class_value(dados_treinamento, [feature], ' ', None)\n",
    "        replace_class_value(dados_teste, [feature], ' ', None)\n",
    "\n",
    "        # Converte os valores str da coluna em numéricos. Coerce substitui strings inválidas por NaN.\n",
    "        dados_treinamento[feature] = pd.to_numeric(dados_treinamento[feature], errors='coerce')\n",
    "        dados_teste[feature] = pd.to_numeric(dados_teste[feature], errors='coerce')\n",
    "\n",
    "        # Substituindo os valores NaN pela mediana.\n",
    "        mediana_feature_treinamento = dados_treinamento[feature].median()\n",
    "        mediana_feature_teste = dados_teste[feature].median()\n",
    "        dados_treinamento[feature] = dados_treinamento[feature].fillna(mediana_feature_treinamento)\n",
    "        dados_teste[feature] = dados_teste[feature].fillna(mediana_feature_teste)\n",
    "\n",
    "    else:\n",
    "        mediana_feature_treinamento = dados_treinamento[feature].median()\n",
    "        mediana_feature_teste = dados_teste[feature].median()\n",
    "        dados_treinamento[feature] = dados_treinamento[feature].fillna(mediana_feature_treinamento)\n",
    "        dados_teste[feature] = dados_teste[feature].fillna(mediana_feature_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfc-royaZKq0",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 07 - Criação e Aplicação de uma Função para Calcular a Taxa de Inadimplência de cada Classe das Features Categóricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F1BhfDqVZMBe"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "#  Criação de uma função para calcular a taxa de inadimplência de cada classe\n",
    "#  das features categóricas.\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def calculate_classes_target_rate(data, target, features=False):\n",
    "    \"Função que calcula a taxa do alvo de cada classe das features categóricas.\"\n",
    "\n",
    "    if features:\n",
    "        features_list = features\n",
    "\n",
    "    else:\n",
    "        features_list = list(data.columns)\n",
    "\n",
    "    for feature in features_list:\n",
    "        print(f\"\\n\\n\\t-----Taxa de '{target}' para as categorias da feature '{feature}'-----\\n\")\n",
    "        dicionario_feature = dict(data[feature].value_counts())\n",
    "        for categoria, quantidade in dicionario_feature.items():\n",
    "            quantidade_target = data[data[feature] == categoria][target].sum()\n",
    "            taxa_target = (quantidade_target / quantidade) * 100\n",
    "            print(f\"Categoria: {categoria}\")\n",
    "            print(f\"Quantidade Total: {quantidade}\")\n",
    "            print(f\"Quantidade {target.title()}: {quantidade_target}\")\n",
    "            print(f\"Taxa de {target.title()}: {taxa_target:.3f}%\\n\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#  Calculando a taxa de inadimplência das classes de cada feature categórica\n",
    "#  Obs: Como foi observado que nas features que apresentavam apenas duas classes,\n",
    "#  a taxa de inadimplência era de 49%-51% para cada, só foram adicionadas à lista\n",
    "#  abaixo as features que possuíam mais de duas classes\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "features_categoricas = ['produto_solicitado', 'forma_envio_solicitacao', 'estado_civil', 'estado_onde_nasceu',\n",
    "                        'estado_onde_reside', 'tipo_residencia', 'estado_onde_trabalha', 'profissao', 'ocupacao',\n",
    "                        'profissao_companheiro', 'sexo', 'codigo_area_telefone_residencial',\n",
    "                        'codigo_area_telefone_trabalho']\n",
    "\n",
    "calculate_classes_target_rate(dados_treinamento, \"inadimplente\", features_categoricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUlM4S7PtSaq",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 08 - Criação e Aplicação de uma Função para Dividir as Classes Numéricas de uma ou mais Features em 4 Partes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vq3kz_wStkPY"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Criação de uma função para dividir as classes numéricas de uma ou mais features\n",
    "# em 4 partes, através dos quartis.\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def divide_classes_by_quartiles(data, features):\n",
    "    \"Função que divide as classes numéricas de uma ou mais features em 4 partes, através dos quartis.\"\n",
    "\n",
    "    for feature in features:\n",
    "        # Garantir que a coluna seja numérica\n",
    "        data[feature] = pd.to_numeric(data[feature], errors='coerce')\n",
    "\n",
    "        # Obter os quartis e estatísticas descritivas\n",
    "        descricao_estatistica_feature = dict(data[feature].describe())\n",
    "        minimo = descricao_estatistica_feature['min']\n",
    "        primeiro_quartil = descricao_estatistica_feature['25%']\n",
    "        mediana = descricao_estatistica_feature['50%']\n",
    "        terceiro_quartil = descricao_estatistica_feature['75%']\n",
    "        maximo = descricao_estatistica_feature['max']\n",
    "\n",
    "        # Função interna para classificar os valores.\n",
    "        def classify_by_quartiles(classe):\n",
    "\n",
    "            # Ignorar valores NaN e ' '.\n",
    "            if pd.isna(classe) or (classe == ' '):\n",
    "                return classe\n",
    "\n",
    "            elif minimo <= classe <= primeiro_quartil:\n",
    "                return 'primeira_particao'\n",
    "\n",
    "            elif primeiro_quartil < classe <= mediana:\n",
    "                return 'segunda_particao'\n",
    "\n",
    "            elif mediana < classe <= terceiro_quartil:\n",
    "                return 'terceira_particao'\n",
    "\n",
    "            elif terceiro_quartil < classe <= maximo:\n",
    "                return 'quarta_particao'\n",
    "\n",
    "        # Aplicar a classificação à cada classe da coluna.\n",
    "        data[feature] = data[feature].apply(classify_by_quartiles)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Aplicação da função 'dividir_classes_por_quartis' em features que possuem\n",
    "# números como classe, onde o significado desses números não foi informado\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "features_significado_nao_informado = ['codigo_area_telefone_residencial', 'codigo_area_telefone_trabalho', 'estado_civil',\n",
    "                                      'tipo_residencia', 'profissao', 'ocupacao', 'profissao_companheiro']\n",
    "\n",
    "divide_classes_by_quartiles(dados_treinamento, features_significado_nao_informado)\n",
    "divide_classes_by_quartiles(dados_teste, features_significado_nao_informado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bKmm1dpuCdI",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 09 - Criação e Implementação de uma Função para Aplicar a Classe OneHotEncoder em Colunas Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8l_zoDXPuMdz"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Criação e implementação de uma função para aplicar a classe OneHotEncoder em\n",
    "# colunas categóricas, mantendo as demais inalteradas.\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def apply_one_hot_encoder(data, features, target=False):\n",
    "    \"Função que aplica a classe OneHotEncoder em features categóricas, mantendo as demais inalteradas.\"\n",
    "\n",
    "    # Separar a coluna do alvo das demais features.\n",
    "    if target:\n",
    "        data_target = data[target]\n",
    "        data_features = data.drop(target, axis=1)\n",
    "\n",
    "    else:\n",
    "        data_target = None\n",
    "        data_features = data\n",
    "\n",
    "    # Substituindo espaços (' ') por underlines ('_').\n",
    "    for feature in features:\n",
    "        data_features[feature] = data_features[feature].replace({' ': '_'})\n",
    "\n",
    "    # Instanciar o OneHotEncoder.\n",
    "    one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "    # Aplicar o OneHotEncoder às colunas categóricas.\n",
    "    data_codificado = one_hot_encoder.fit_transform(data_features[features])\n",
    "\n",
    "    # Colhetando os nomes das features codificadas.\n",
    "    features_codificadas = one_hot_encoder.get_feature_names_out(features)\n",
    "\n",
    "    # Converter o resultado para DataFrame.\n",
    "    data_frame_codificado = pd.DataFrame(data_codificado, columns=features_codificadas, index=data.index)\n",
    "\n",
    "    # Remover as features categóricas originais.\n",
    "    data_features = data_features.drop(columns=features)\n",
    "\n",
    "    data_final = pd.concat([data_features, data_frame_codificado, data_target], axis=1)\n",
    "    return data_final\n",
    "\n",
    "\n",
    "# Implementação da função.\n",
    "dados_treinamento = apply_one_hot_encoder(dados_treinamento, features_categoricas, 'inadimplente')\n",
    "dados_teste = apply_one_hot_encoder(dados_teste, features_categoricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9Hy6Jccu3-Z",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 10 - Remoção das Features dos Estados Inválidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "28dmCNTGu74e"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Removendo as features dos estados inválidos.\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "estados_invalidos = ['estado_onde_nasceu_classe_invalida', 'estado_onde_trabalha_classe_invalida']\n",
    "dados_treinamento.drop(estados_invalidos, axis=1, inplace=True)\n",
    "dados_teste.drop(estados_invalidos, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzBn62ltvGAG",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 11 - Exibição dos Coeficientes de Pearson de Cada Atributo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yDBqcpNvHYu"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Exibindo os coeficientes de Pearson de cada atributo (entre o mesmo e o alvo)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Coeficiente de Pearson-----\\n\")\n",
    "for coluna in dados_treinamento.columns:\n",
    "    coef_pearsonr = pearsonr(dados_treinamento[coluna], dados_treinamento['inadimplente'])[0]\n",
    "    p_value = pearsonr(dados_treinamento[coluna], dados_treinamento['inadimplente'])[1]\n",
    "    print(f'{coluna}: {coef_pearsonr:.3f}, p-value: {p_value:.3f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "td2qL55nvn96",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 12 - Remoção de Features que Possuíam Um Coeficiente de Pearson Menor que 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dhR3xhkcv0Xp"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Remoção de features que possuíam um coeficiente de Pearson menor que 0.01\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "drop_list_pearson = ['codigo_area_telefone_residencial_terceira_particao', 'ocupacao_quarta_particao',\n",
    "              'estado_onde_trabalha_regiao_sul', 'estado_onde_trabalha_regiao_sudeste', 'estado_onde_trabalha_regiao_norte',\n",
    "              'estado_onde_reside_regiao_sudeste', 'estado_onde_nasceu_regiao_sudeste', 'estado_onde_nasceu_regiao_norte',\n",
    "              'forma_envio_solicitacao_internet', 'produto_solicitado_2', 'vinculo_formal_com_empresa', 'possui_cartao_visa',\n",
    "              'renda_extra', 'renda_mensal_regular', 'possui_email', 'sexo_N']\n",
    "\n",
    "dados_treinamento.drop(drop_list_pearson, axis=1, inplace=True)\n",
    "dados_teste.drop(drop_list_pearson, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OO68CLuBv_nH",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 13 - Exibição dos Histogramas entre as Quantidades e Valores de Cada Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FdVjodO1wL5Z"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Exibindo os histogramas entre as quantidades e valores de cada feature\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "for feature in list(dados_treinamento.columns):\n",
    "    print(f\"\\n\\n\\t-----Histograma da feature {feature}-----\\n\")\n",
    "    grafico = dados_treinamento[feature].plot.hist(bins=100)\n",
    "    grafico.set(title=feature, xlabel='Valores', ylabel='Quantidades')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCQshDWywgX1",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 14 - Embaralhamento do Conjunto de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BQcUgqHrwnKB"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Embaralhar o conjunto de dados de treino para garantir que a divisão entre os\n",
    "# dados esteja isenta de qualquer viés de seleção\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "dados_treinamento_embaralhados = dados_treinamento.sample(frac=1, random_state=11012005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T01Qf5x7wt3F",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 15 - Separação do Conjunto de Treinamento em Arrays X e Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Waq1_0Esw1_e"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Separar o conjunto de treinamento em arrays X e Y\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Separando as features do alvo.\n",
    "X = dados_treinamento_embaralhados.iloc[:, :-1].values\n",
    "y = dados_treinamento_embaralhados.iloc[:, -1].values\n",
    "\n",
    "# Conjunto de treino e teste\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.25, random_state=11012005)\n",
    "\n",
    "# Conjunto de teste final\n",
    "X_teste_final = dados_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4Z4IFQHxCHP",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 16 - Aplicação da Escala no X de Treino e de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74apVRP6xF1O"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Aplicação da escala no X de treino e de teste\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Neste caso, os melhores resultados foram encontrados com o StandardScaler()\n",
    "# escala = MinMaxScaler()\n",
    "escala = StandardScaler()\n",
    "\n",
    "escala.fit(X_treino)\n",
    "X_treino_com_escala = escala.transform(X_treino)\n",
    "X_teste_com_escala = escala.transform(X_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FJ5oB3_0jzW",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 17 - Treinamento do Modelo KNeighborsClassifier\n",
    "\n",
    "- Melhor resultado: n_neighbors = 24, acurácia = 56,12%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BI-0AWLo0sUI"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Treinando o modelo KNeighborsClassifier, com k variando entre 1 e 30\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Classificador com KNN-----\\n\")\n",
    "for k in range(1, 31):\n",
    "    # Instanciando o classificador KNN.\n",
    "    classificador_knn = KNeighborsClassifier(n_neighbors=k, weights=\"uniform\")\n",
    "    classificador_knn = classificador_knn.fit(X_treino_com_escala, y_treino)\n",
    "\n",
    "    y_resposta_treino = classificador_knn.predict(X_treino_com_escala)\n",
    "    y_resposta_teste = classificador_knn.predict(X_teste_com_escala)\n",
    "\n",
    "    acuracia_treino = accuracy_score(y_treino, y_resposta_treino)\n",
    "    acuracia_teste = accuracy_score(y_teste, y_resposta_teste)\n",
    "\n",
    "    print(f'\\nK = {k}')\n",
    "    print(f'Acurácia Treino: {(acuracia_treino * 100):.4f}%')\n",
    "    print(f'Taxa de Erro Treino: {((1 - acuracia_treino) * 100):.4f}%')\n",
    "    print(f'Acurácia Teste: {(acuracia_teste * 100):.4f}%')\n",
    "    print(f'Taxa de Erro Teste: {((1 - acuracia_teste) * 100):.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vq-NvGtnWq6M",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 18 - Treinamento do Modelo Regressão Logística\n",
    "- Melhor resultado (sem validação cruzada): penalty = 'l2', C = 0.002500, acurácia = 60.1%\n",
    "- Melhor resultado (com validação cruzada): cv = 4, penalty = 'l2', Cs = [0.0015, 0.0016, 0.0017, 0.0018, 0.0019, 0.002, 0.00205, 0.0021, 0.00215, 0.0022, 0.0025], acurácia = 60.1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yuIcyBvfXVt7"
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "# Treinando o modelo LogisticRegression, com penalidade L2\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Classificador com Regressão Logística (Regularização L2)-----\\n\")\n",
    "print(\"\\n             C TREINO  TESTE\")\n",
    "print(\" ------------- ------  -----\")\n",
    "\n",
    "# Para este laço, o melhor resultado foi em C=0.010000 (59.9% de acurácia).\n",
    "# for c in [0.000001, 0.000010, 0.000100, 0.001, 0.010, 0.100,\n",
    "          # 1, 10, 100, 1000, 10000, 100000, 1000000]:\n",
    "\n",
    "# Para este laço, os melhores resultados foram em C=0.002000/acurácia=60.0% e em C=0.005000/acurácia=60.0%.\n",
    "# for c in [0.00100, 0.00200, 0.00500, 0.01000, 0.02000, 0.05000, 0.10000]:\n",
    "\n",
    "# Para este laço, o melhor resultado foi em C=0.002500 (60.1% de acurácia)\n",
    "# for c in [0.00100, 0.00150, 0.00180, 0.00200, 0.00250, 0.00300, 0.00350, 0.00400, 0.00450, 0.00500, 0.00550, 0.00600, 0.00700, 0.00800, 0.010000]:\n",
    "\n",
    "# Por fim, decidimos que o melhor valor de c é 0.002500.\n",
    "c = 0.002500\n",
    "\n",
    "classificador_lr = LogisticRegression(penalty='l2', C=c, max_iter=100000)\n",
    "classificador_lr = classificador_lr.fit(X_treino_com_escala, y_treino)\n",
    "\n",
    "y_resposta_treino = classificador_lr.predict(X_treino_com_escala)\n",
    "y_resposta_teste = classificador_lr.predict(X_teste_com_escala)\n",
    "\n",
    "acuracia_treino = accuracy_score(y_treino, y_resposta_treino)\n",
    "acuracia_teste = accuracy_score(y_teste, y_resposta_teste)\n",
    "\n",
    "print(\n",
    "    \"%14.6f\" % c,\n",
    "    \"%6.1f\" % (100 * acuracia_treino),\n",
    "    \"%6.1f\" % (100 * acuracia_teste)\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Treinando o modelo LogisticRegressionCV, com penalidade L2 e validação cruzada\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Classificador com Regressão Logística (Regularização L2 e Validação Cruzada)-----\\n\")\n",
    "print(\"\\n             C TREINO  TESTE\")\n",
    "print(\" ------------- ------  -----\")\n",
    "\n",
    "classificador_lr_cv = LogisticRegressionCV(cv=4, max_iter=100000, penalty='l2',\n",
    "                                           # Último laço da Regressão Logística sem validação cruzada.\n",
    "                                           Cs=[0.0015, 0.0016, 0.0017, 0.0018, 0.0019, 0.002, 0.00205, 0.0021, 0.00215,\n",
    "                                               0.0022, 0.0025])\n",
    "\n",
    "classificador_lr_cv = classificador_lr_cv.fit(X_treino_com_escala, y_treino)\n",
    "\n",
    "y_resposta_treino = classificador_lr_cv.predict(X_treino_com_escala)\n",
    "y_resposta_teste = classificador_lr_cv.predict(X_teste_com_escala)\n",
    "\n",
    "acuracia_treino = accuracy_score(y_treino, y_resposta_treino)\n",
    "acuracia_teste = accuracy_score(y_teste, y_resposta_teste)\n",
    "\n",
    "print(\n",
    "    \"%14.6f\" % c,\n",
    "    \"%6.1f\" % (100 * acuracia_treino),\n",
    "    \"%6.1f\" % (100 * acuracia_teste)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WiZp9BcnXske",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 19 - Treinamento do Modelo Bayesiano Ingênuo\n",
    "\n",
    "- Melhor resultado BernoulliNB: 57.58% de acurácia\n",
    "- Melhor resultado GaussianNB: 55.6% de acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1vOdwbbQX04X"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\\n\\t-----Classificador Bayesiano Ingênuo-----\\n\")\n",
    "\n",
    "print('\\nBernoulliNB:\\n')\n",
    "classificador_bernoullinb = BernoulliNB()\n",
    "classificador_bernoullinb = classificador_bernoullinb.fit(X_treino_com_escala, y_treino)\n",
    "\n",
    "y_resposta_treino = classificador_bernoullinb.predict(X_treino_com_escala)\n",
    "y_resposta_teste = classificador_bernoullinb.predict(X_teste_com_escala)\n",
    "\n",
    "acuracia_treino = accuracy_score(y_treino, y_resposta_treino)\n",
    "acuracia_teste = accuracy_score(y_teste, y_resposta_teste)\n",
    "\n",
    "print(f'Acurácia Treino: {(acuracia_treino * 100):.4f}%')\n",
    "print(f'Taxa de Erro Treino: {((1 - acuracia_treino) * 100):.4f}%')\n",
    "print(f'Acurácia Teste: {(acuracia_teste * 100):.4f}%')\n",
    "print(f'Taxa de Erro Teste: {((1 - acuracia_teste) * 100):.4f}%')\n",
    "\n",
    "# Parte comentada, pois somente funcionava com a escala MinMaxScaler().\n",
    "# print('\\nMultinomial:\\n')\n",
    "# classificador_multinomial = MultinomialNB()\n",
    "# classificador_multinomial = classificador_multinomial.fit(X_treino_com_escala, y_treino)\n",
    "#\n",
    "# y_resposta_treino = classificador_multinomial.predict(X_treino_com_escala)\n",
    "# y_resposta_teste = classificador_multinomial.predict(X_teste_com_escala)\n",
    "#\n",
    "# acuracia_treino = accuracy_score(y_treino, y_resposta_treino)\n",
    "# acuracia_teste = accuracy_score(y_teste, y_resposta_teste)\n",
    "#\n",
    "# print(f'Acurácia Treino: {(acuracia_treino*100):.4f}%')\n",
    "# print(f'Taxa de Erro Treino: {((1-acuracia_treino)*100):.4f}%')\n",
    "# print(f'Acurácia Teste: {(acuracia_teste*100):.4f}%')\n",
    "# print(f'Taxa de Erro Teste: {((1-acuracia_teste)*100):.4f}%')\n",
    "\n",
    "print('\\nGaussianNB:\\n')\n",
    "classificador_gaussiannb = GaussianNB()\n",
    "classificador_gaussiannb = classificador_gaussiannb.fit(X_treino_com_escala, y_treino)\n",
    "\n",
    "y_resposta_treino = classificador_gaussiannb.predict(X_treino_com_escala)\n",
    "y_resposta_teste = classificador_gaussiannb.predict(X_teste_com_escala)\n",
    "\n",
    "acuracia_treino = accuracy_score(y_treino, y_resposta_treino)\n",
    "acuracia_teste = accuracy_score(y_teste, y_resposta_teste)\n",
    "\n",
    "print(f'Acurácia Treino: {(acuracia_treino * 100):.4f}%')\n",
    "print(f'Taxa de Erro Treino: {((1 - acuracia_treino) * 100):.4f}%')\n",
    "print(f'Acurácia Teste: {(acuracia_teste * 100):.4f}%')\n",
    "print(f'Taxa de Erro Teste: {((1 - acuracia_teste) * 100):.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-b4KnQVMYRF0",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 20 - Treinamento do Modelo Support Vector Machine\n",
    "\n",
    "- Melhor resultado SVM Linear: penalty = 'l2', C = 0.000900, acurácia = 60.04%\n",
    "- Melhor resultado SVM com Kernel: kernel = 'rbf', C = 4, gamma = 0.0010, acurácia = 60.50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H_g19HqEYVbd"
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "# Treinando o classificador Support Vector Machine Linear\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Classificador Support Vector Machine Linear-----\\n\")\n",
    "\n",
    "print(\"\\n           C  ACCTRE  ACCTES  ERRTRE  ERRTES\")\n",
    "print(\" -----------  ------  ------  ------  ------\")\n",
    "\n",
    "# Para este laço, os melhores resultados foram em C=0.001000 com 59.94% de acurácia.\n",
    "# for C in [0.000001, 0.000010, 0.000100, 0.001000, 0.010000, 0.100000]:\n",
    "\n",
    "# Para este laço, o melhor resultado foi em C=0.000900 com 60.04% de acurácia.\n",
    "# for C in [0.00010, 0.00020, 0.00050, 0.00080, 0.00090, 0.00100, 0.00200,  0.00300, 0.00500,  0.00800, 0.001000]:\n",
    "\n",
    "# Para este laço, o melhor resultado ainda foi em C=0.000900 com 60.04% de acurácia.\n",
    "# for C in [0.00080, 0.00081, 0.00082, 0.00083, 0.00084, 0.00085, 0.00086, 0.00087, 0.00088, 0.00089, 0.00090,\n",
    "# 0.00091, 0.00092, 0.00093, 0.00094, 0.00095, 0.00096, 0.00097, 0.00098, 0.00099, 0.00100]:\n",
    "\n",
    "# Por fim, escolhemos C=0.000900.\n",
    "C = 0.000900\n",
    "\n",
    "classificador_linear_svc = LinearSVC(penalty='l2', C=C, max_iter=10000000, dual=True, random_state=11012005)\n",
    "classificador_linear_svc = classificador_linear_svc.fit(X_treino_com_escala, y_treino)\n",
    "\n",
    "y_resposta_treino = classificador_linear_svc.predict(X_treino_com_escala)\n",
    "y_resposta_teste = classificador_linear_svc.predict(X_teste_com_escala)\n",
    "\n",
    "acuracia_treino = accuracy_score(y_treino, y_resposta_treino)\n",
    "acuracia_teste = accuracy_score(y_teste, y_resposta_teste)\n",
    "\n",
    "print(\n",
    "    # \"%3d\"%k,\n",
    "    \"%11.6f\" % C,\n",
    "    \"%8.2f\" % (100 * acuracia_treino),\n",
    "    \"%7.2f\" % (100 * acuracia_teste),\n",
    "    \"%7.2f\" % (100 - 100 * acuracia_treino),\n",
    "    \"%7.2f\" % (100 - 100 * acuracia_teste)\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Treinando o classificador Support Vector Machine com Kernel\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Classificador Support Vector Machine com Kernel-----\\n\")\n",
    "print(\"\\n       C    GAMMA  TREINO  TESTE\")\n",
    "print(\" -------  -------  ------  ------\")\n",
    "\n",
    "# Para este laço, o melhor resultado foi em c=10/g=0.0010/acurácia=60.32%.\n",
    "# for g in [0.000100, 0.001, 0.010, 0.100, 1, 10, 100, 1000, 10000, 100000, 1000000]:\n",
    "# for c in [0.010, 0.100, 1, 10, 100, 1000, 10000, 100000, 1000000]:\n",
    "\n",
    "# Para este laço, o melhor resultado foi em c=4/acurácia=60.50%.\n",
    "# g = 0.001\n",
    "# for c in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40, 50, 60, 70, 80, 90, 100]:\n",
    "\n",
    "# Por fim, escolhemos c = 4 e g = 0.0010 --> acurácia = 60.50%\n",
    "c = 4\n",
    "g = 0.0010\n",
    "\n",
    "classificador_svc = SVC(kernel='rbf', C=c, gamma=g, max_iter=100000000)\n",
    "classificador_svc = classificador_svc.fit(X_treino_com_escala, y_treino)\n",
    "\n",
    "y_resposta_treino = classificador_svc.predict(X_treino_com_escala)\n",
    "y_resposta_teste = classificador_svc.predict(X_teste_com_escala)\n",
    "\n",
    "acuracia_treino = accuracy_score(y_treino, y_resposta_treino)\n",
    "acuracia_teste = accuracy_score(y_teste, y_resposta_teste)\n",
    "\n",
    "print(\n",
    "    \"%9.4f\" % c,\n",
    "    \"%9.4f\" % g,\n",
    "    \"%6.2f\" % (100 * acuracia_treino),\n",
    "    \"%6.2f\" % (100 * acuracia_teste)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuF9gwVrZnQ8",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 21 - Treinando o Modelo Árvore de Decisão\n",
    "\n",
    "- Melhor resultado: criterion = 'gini', max_depth = 5, acurácia = 57.98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oneZ7uRqZvc_"
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "# Treinando o classificador Árvore de Decisão, variando a profundidade\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Classificador Árvore de Decisão-----\\n\")\n",
    "print(\"\\n  D TREINO  TESTE\")\n",
    "print(\" -- ------ ------\")\n",
    "\n",
    "# Para este laço, o melhor resultado foi em d=5 e criterion='gini', com 57.98% de acurácia.\n",
    "# for d in range(2, 21):\n",
    "\n",
    "d = 5\n",
    "# criterion = 'gini', 'entropy' ou 'log_loss'\n",
    "classificador_arvore_decisao = DecisionTreeClassifier(criterion='gini', max_depth=d, random_state=11012005)\n",
    "classificador_arvore_decisao = classificador_arvore_decisao.fit(X_treino_com_escala, y_treino)\n",
    "\n",
    "y_resposta_treino = classificador_arvore_decisao.predict(X_treino_com_escala)\n",
    "y_resposta_teste = classificador_arvore_decisao.predict(X_teste_com_escala)\n",
    "\n",
    "acuracia_treino = accuracy_score(y_treino, y_resposta_treino)\n",
    "acuracia_teste = accuracy_score(y_teste, y_resposta_teste)\n",
    "\n",
    "print(\n",
    "    \"%3d\" % d,\n",
    "    \"%6.2f\" % (100 * acuracia_treino),\n",
    "    \"%6.2f\" % (100 * acuracia_teste)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMeEbdPiZ-MO",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 22 - Treinando o Modelo Floresta Aleatória\n",
    "\n",
    "- Melhor resultado (sem Filtro de Feature Importance): n_estimators = 65, max_features = 9, max_depth = 10, acurácia = 60.90%\n",
    "\n",
    "- Melhor resultado (com Filtro de Feature Importance): n_estimators = 205, max_features = 8, max_depth = 10, acurácia = 61.10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPgQQqPIaUAc"
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "# Treinando o classificador Floresta Aleatória\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Classificador Floresta Aleatória-----\\n\")\n",
    "print(\"\\n  K   D TREINO  TESTE   ERRO  oob_score\")\n",
    "print(\"  -- -- ------ ------ ------ -----\")\n",
    "\n",
    "# Para este laço, o melhor resultado foi em k=65/acurácia=60.90%/max_features=9.\n",
    "# d = 10\n",
    "# for k in range(5, 501, 5):\n",
    "\n",
    "# Para este laço, o melhor resultado foi em k=65/d=10/acurácia=60.90%/max_features=9.\n",
    "# d = 10\n",
    "# for k in [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70]:\n",
    "\n",
    "# Para este laço, o melhor resultado ainda foi em k=65/d=10/acurácia=60.90%/max_features=9.\n",
    "# k = 65\n",
    "# for d in range(2, 21):\n",
    "\n",
    "# Por fim, escolhemos k = 65, d = 10, max_features = 9 --> acurácia = 60.90%.\n",
    "k = 65\n",
    "d = 10\n",
    "\n",
    "classificador_floresta_aleatoria = RandomForestClassifier(\n",
    "    n_estimators=k,\n",
    "    max_features=9,\n",
    "    oob_score=True,\n",
    "    max_depth=d,\n",
    "    random_state=11012005\n",
    ")\n",
    "\n",
    "classificador_floresta_aleatoria = classificador_floresta_aleatoria.fit(X_treino_com_escala, y_treino)\n",
    "\n",
    "y_resposta_treino = classificador_floresta_aleatoria.predict(X_treino_com_escala)\n",
    "y_resposta_teste = classificador_floresta_aleatoria.predict(X_teste_com_escala)\n",
    "\n",
    "acuracia_treino = accuracy_score(y_treino, y_resposta_treino)\n",
    "acuracia_teste = accuracy_score(y_teste, y_resposta_teste)\n",
    "\n",
    "print(\n",
    "    \"%3d\" % k,\n",
    "    \"%3d\" % d,\n",
    "    \"%6.2f\" % (100 * acuracia_treino),\n",
    "    \"%6.2f\" % (100 * acuracia_teste),\n",
    "    \"%6.2f\" % (100 * (1 - acuracia_teste)),\n",
    "    \"%6.2f\" % (100 * classificador_floresta_aleatoria.oob_score_)\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "# Treinando o classificador Floresta Aleatória com Filtro de Feature Importance\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Classificador Floresta Aleatória (Filtro de Feature Importance)-----\\n\")\n",
    "print(\"\\n  K   D TREINO  TESTE   ERRO\")\n",
    "print(\"  -- -- ------ ------ ------\")\n",
    "\n",
    "# Treinamento de um modelo inicial (tendo como base os valores anteriores de 'k' e 'd')\n",
    "k = 65\n",
    "d = 10\n",
    "classificador_floresta_aleatoria = RandomForestClassifier(\n",
    "    n_estimators=k,\n",
    "    max_features=9,\n",
    "    oob_score=True,\n",
    "    max_depth=d,\n",
    "    random_state=11012005\n",
    ")\n",
    "classificador_floresta_aleatoria = classificador_floresta_aleatoria.fit(X_treino_com_escala, y_treino)\n",
    "\n",
    "# Filtrando as features, para que apenas as que possuem importância superior a 0.01 sejam mantidas.\n",
    "X_treino_reduzido = X_treino_com_escala[:, classificador_floresta_aleatoria.feature_importances_ > 0.01]\n",
    "X_teste_reduzido = X_teste_com_escala[:, classificador_floresta_aleatoria.feature_importances_ > 0.01]\n",
    "\n",
    "\n",
    "# Para este laço, o melhor resultado foi em k=205/d=10/acurácia=61.10%/max_features=8.\n",
    "# d = 10\n",
    "# for k in range(5, 251, 5):\n",
    "\n",
    "# Para este laço, o melhor resultado ainda foi em k=205/d=10/acurácia=61.10%/max_features=8.\n",
    "# d = 10\n",
    "# for k in [200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210]:\n",
    "\n",
    "# Para este laço, o melhor resultado ainda foi em k=205/d=10/acurácia=61.10%/max_features=8.\n",
    "# k = 170\n",
    "# for d in range(2, 21):\n",
    "\n",
    "# Por fim, escolhemos k = 205, d = 10, max_features = 8 --> acurácia = 61.10%.\n",
    "k = 205\n",
    "d = 10\n",
    "\n",
    "# Treinamento final do modelo.\n",
    "classificador_floresta_aleatoria = RandomForestClassifier(\n",
    "    n_estimators=k,\n",
    "    max_features=8,\n",
    "    oob_score=False,\n",
    "    max_depth=d,\n",
    "    random_state=11012005\n",
    ")\n",
    "\n",
    "classificador_floresta_aleatoria = classificador_floresta_aleatoria.fit(X_treino_reduzido, y_treino)\n",
    "\n",
    "y_resposta_treino = classificador_floresta_aleatoria.predict(X_treino_reduzido)\n",
    "y_resposta_teste = classificador_floresta_aleatoria.predict(X_teste_reduzido)\n",
    "\n",
    "acuracia_treino = accuracy_score(y_treino, y_resposta_treino)\n",
    "acuracia_teste = accuracy_score(y_teste, y_resposta_teste)\n",
    "\n",
    "print(\n",
    "    \"%3d\" % k,\n",
    "    \"%3d\" % d,\n",
    "    \"%6.2f\" % (100*acuracia_treino),\n",
    "    \"%6.2f\" % (100*acuracia_teste),\n",
    "    \"%6.2f\" % (100*(1-acuracia_teste))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEOKJez2hmC3",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 23 - Treinamento da Submissão Final para o Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNZraz08h0Lz"
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "# Treinando a submissão final para o Kaggle, com o modelo que obteve a maior\n",
    "# acurácia (Floresta Aleatória com Feature Importance).\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "# Utilizando todos os dados.\n",
    "X_treino_submissao = X\n",
    "X_teste_submissao = X_teste_final\n",
    "y_treino_submissao = y\n",
    "\n",
    "# Colocando em escala.\n",
    "escala = StandardScaler()\n",
    "escala.fit(X_treino_submissao)\n",
    "X_treino_submissao_com_escala = escala.transform(X_treino_submissao)\n",
    "X_teste_submissao_com_escala = escala.transform(X_teste_submissao)\n",
    "\n",
    "# Treinando um modelo inicial, a fim de realizar o filtro das importâncias das features.\n",
    "k = 65\n",
    "d = 10\n",
    "classificador_floresta_aleatoria = RandomForestClassifier(\n",
    "    n_estimators=k,\n",
    "    max_features=9,\n",
    "    oob_score=True,\n",
    "    max_depth=d,\n",
    "    random_state=11012005\n",
    ")\n",
    "classificador_floresta_aleatoria = classificador_floresta_aleatoria.fit(X_treino_submissao_com_escala, y_treino_submissao)\n",
    "X_treino_reduzido = X_treino_submissao_com_escala[:, classificador_floresta_aleatoria.feature_importances_ > 0.01]\n",
    "X_teste_reduzido = X_teste_submissao_com_escala[:, classificador_floresta_aleatoria.feature_importances_ > 0.01]\n",
    "\n",
    "# Treinando o modelo definitivo.\n",
    "k = 205\n",
    "d = 10\n",
    "classificador_floresta_aleatoria = RandomForestClassifier(\n",
    "    n_estimators=k,\n",
    "    max_features=8,\n",
    "    oob_score=False,\n",
    "    max_depth=d,\n",
    "    random_state=11012005\n",
    ")\n",
    "classificador_floresta_aleatoria = classificador_floresta_aleatoria.fit(X_treino_reduzido, y_treino_submissao)\n",
    "y_resposta_teste_submissao = classificador_floresta_aleatoria.predict(X_teste_reduzido)\n",
    "\n",
    "# Criando o DataFrame de submissão.\n",
    "submissao_final_kaggle = pd.DataFrame({\n",
    "    'id_solicitante': ids_solicitantes_dados_teste,\n",
    "    'inadimplente': y_resposta_teste_submissao\n",
    "})\n",
    "\n",
    "# Salvando em CSV\n",
    "submissao_final_kaggle.to_csv('submissao_final_kaggle.csv', index=False)\n",
    "print(\"Arquivo salvo como 'submissao_final_kaggle.csv'\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "3YXpnSjKP4Dj",
    "tdU0vMRKQTBL",
    "m0t6XPLv2aHz",
    "ues0Dslb2_oj",
    "FzTEd8k03KHj",
    "Q5_0XKWtVQZk",
    "xfc-royaZKq0",
    "eUlM4S7PtSaq",
    "5bKmm1dpuCdI",
    "q9Hy6Jccu3-Z",
    "fzBn62ltvGAG",
    "td2qL55nvn96",
    "OO68CLuBv_nH",
    "YCQshDWywgX1",
    "T01Qf5x7wt3F",
    "R4Z4IFQHxCHP",
    "5FJ5oB3_0jzW",
    "Vq-NvGtnWq6M",
    "WiZp9BcnXske",
    "-b4KnQVMYRF0",
    "xuF9gwVrZnQ8",
    "lMeEbdPiZ-MO",
    "wEOKJez2hmC3"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
