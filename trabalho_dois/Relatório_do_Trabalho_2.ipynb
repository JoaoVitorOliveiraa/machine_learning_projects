{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1c0KMURNCGr"
   },
   "source": [
    "# Relatório do Trabalho 2 - Introdução ao Aprendizado de Máquina\n",
    "### Aluno: João Vitor dos Santos Oliveira\n",
    "### Professor: Heraldo Almeida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YXpnSjKP4Dj",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 01 - Importação das Bibliotecas Utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E29fv_4yQMjU"
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Importar bibliotecas\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdU0vMRKQTBL",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 02 - Importação dos Conjuntos de Teste e Treinamento\n",
    "\n",
    "- Observação: Salvei os conjuntos em um diretório de nome 'data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "MR6K-vogRZJs",
    "outputId": "72943316-0b4d-41a3-bdd7-50150399b65a"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/conjunto_de_teste.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8a9597fa07f7>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcaminho_conjunto_de_teste\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'conjunto_de_teste.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcaminho_conjunto_de_treinamento\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'conjunto_de_treinamento.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdados_teste\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaminho_conjunto_de_teste\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdados_treinamento\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaminho_conjunto_de_treinamento\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mids_solicitantes_dados_teste\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdados_teste\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id_solicitante'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/conjunto_de_teste.csv'"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Importar os conjuntos de teste e treinamento (retirando as colunas dos id's)\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "caminho_conjunto_de_teste = Path('../data') / 'conjunto_de_teste.csv'\n",
    "caminho_conjunto_de_treinamento = Path('../data') / 'conjunto_de_treinamento.csv'\n",
    "dados_treinamento = pd.read_csv(caminho_conjunto_de_treinamento)\n",
    "dados_teste = pd.read_csv(caminho_conjunto_de_teste)\n",
    "ids_dados_teste = dados_teste['Id']\n",
    "dados_teste = dados_teste.iloc[:, 1:]\n",
    "dados_treinamento = dados_treinamento.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0t6XPLv2aHz",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 03 - Análise dos Dados de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "kYw1X4zW2stc",
    "outputId": "71ab5ea3-3e57-4ab2-a470-31bc91d09a50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t-----Dez primeiras linhas do conjunto de treinamento-----\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dados_treinamento' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-dcabbcf7a770>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\t\\t-----Dez primeiras linhas do conjunto de treinamento-----\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdados_treinamento\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# ------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dados_treinamento' is not defined"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "#  Exibição das primeiras 10 linhas do conjunto de treinamento através da função head()\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\t\\t-----Dez primeiras linhas do conjunto de treinamento-----\\n\")\n",
    "print(dados_treinamento.head(n=10))\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#  Descrição dos dados de treinamento (como número de linhas, tipo de cada\n",
    "#  atributo e número de valores não nulos) através da função info()\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Descrição dos dados do conjunto de treinamento-----\\n\")\n",
    "dados_treinamento.info()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#  Descobrindo quais categorias existem nas features e no alvo, além de quantos\n",
    "#  dígitos pertencem a cada categoria, usando a função value_counts()\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Categorias das features e do alvo, com suas respectivas quantidades-----\\n\")\n",
    "for feature in list(dados_treinamento.columns):\n",
    "    print(\"\\n\", dados_treinamento[feature].value_counts())\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#  Resumo dos atributos numéricos do conjunto de treinamento através da\n",
    "#  função describe()\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Resumo dos atributos numéricos-----\\n\")\n",
    "print(dados_treinamento.describe())\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Exibindo as features do dataset e seus tipos\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Features disponíveis-----\\n\")\n",
    "print(list(dados_treinamento.columns))\n",
    "\n",
    "print(\"\\n\\n-----Tipos das features-----\\n\")\n",
    "print(dados_treinamento.dtypes)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Exibindo o histograma entre as quantidades e os valores do alvo\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Histograma do alvo-----\\n\")\n",
    "grafico = dados_treinamento['preco'].plot.hist(bins=100)\n",
    "grafico.set(title='preco', xlabel='Quantidades', ylabel='Valores')\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#  Melhor exibição das classes das features, pois os describe() não exibiu todas\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Melhor exibição das classes das features-----\\n\")\n",
    "for feature in list(dados_treinamento.columns):\n",
    "    print(f\"\\nClasses {feature}: \", list(dados_treinamento[feature].unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bKmm1dpuCdI",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 04 - Criação e Implementação de uma Função para Aplicar a Classe OneHotEncoder em Colunas Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-C6YCnCeBUEA"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Criação e implementação de uma função para aplicar a classe OneHotEncoder em\n",
    "# colunas categóricas, mantendo as demais inalteradas.\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def apply_one_hot_encoder(data, features, target=False):\n",
    "    \"Função que aplica a classe OneHotEncoder em features categóricas, mantendo as demais inalteradas.\"\n",
    "\n",
    "    # Separar a coluna do alvo das demais features.\n",
    "    if target:\n",
    "        data_target = data[target]\n",
    "        data_features = data.drop(target, axis=1)\n",
    "\n",
    "    else:\n",
    "        data_target = None\n",
    "        data_features = data\n",
    "\n",
    "    # Substituindo espaços (' ') por underlines ('_').\n",
    "    for feature in features:\n",
    "        data_features[feature] = data_features[feature].str.replace(' ', '_')\n",
    "\n",
    "    # Instanciar o OneHotEncoder.\n",
    "    one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "    # Aplicar o OneHotEncoder às colunas categóricas.\n",
    "    data_codificado = one_hot_encoder.fit_transform(data_features[features])\n",
    "\n",
    "    # Colhetando os nomes das features codificadas.\n",
    "    features_codificadas = one_hot_encoder.get_feature_names_out(features)\n",
    "\n",
    "    # Converter o resultado para DataFrame.\n",
    "    data_frame_codificado = pd.DataFrame(data_codificado, columns=features_codificadas, index=data.index)\n",
    "\n",
    "    # Remover as features categóricas originais.\n",
    "    data_features = data_features.drop(columns=features)\n",
    "\n",
    "    data_final = pd.concat([data_features, data_frame_codificado, data_target], axis=1)\n",
    "    return data_final\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Implementação da função nas features categóricas dos conjuntos de dados.\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "features_categoricas = ['tipo', 'bairro', 'tipo_vendedor', 'diferenciais']\n",
    "dados_treinamento = apply_one_hot_encoder(dados_treinamento, features_categoricas, 'preco')\n",
    "dados_teste = apply_one_hot_encoder(dados_teste, features_categoricas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_typdZpJBoB8",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 05 - Remoção de Features que Possuíam uma Classe Dominante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qKedw7UABqus"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "#  Remoção de features que possuíam uma classe extremamente dominante\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "features_classes_dominantes = [\n",
    "'s_jogos',\n",
    "'s_ginastica',\n",
    "'tipo_Loft',\n",
    "'tipo_Quitinete',\n",
    "'bairro_Aflitos',\n",
    "'bairro_Afogados',\n",
    "'bairro_Agua_Fria',\n",
    "'bairro_Apipucos',\n",
    "'bairro_Areias',\n",
    "'bairro_Arruda',\n",
    "'bairro_Barro',\n",
    "'bairro_Beira_Rio',\n",
    "'bairro_Benfica',\n",
    "'bairro_Boa_Vista',\n",
    "'bairro_Bongi',\n",
    "'bairro_Cajueiro',\n",
    "'bairro_Campo_Grande',\n",
    "'bairro_Caxanga',\n",
    "'bairro_Centro',\n",
    "'bairro_Cid_Universitaria',\n",
    "'bairro_Coelhos',\n",
    "'bairro_Cohab',\n",
    "'bairro_Cordeiro',\n",
    "'bairro_Derby',\n",
    "'bairro_Dois_Irmaos',\n",
    "'bairro_Engenho_do_Meio',\n",
    "'bairro_Estancia',\n",
    "'bairro_Guabiraba',\n",
    "'bairro_Hipodromo',\n",
    "'bairro_Ilha_do_Leite',\n",
    "'bairro_Ilha_do_Retiro',\n",
    "'bairro_Imbiribeira',\n",
    "'bairro_Ipsep',\n",
    "'bairro_Iputinga',\n",
    "'bairro_Jaqueira',\n",
    "'bairro_Jd_S_Paulo',\n",
    "'bairro_Lagoa_do_Araca',\n",
    "'bairro_Macaxeira',\n",
    "'bairro_Monteiro',\n",
    "'bairro_Paissandu',\n",
    "'bairro_Piedade',\n",
    "'bairro_Pina',\n",
    "'bairro_Poco',\n",
    "'bairro_Poco_da_Panela',\n",
    "'bairro_Ponto_de_Parada',\n",
    "'bairro_Prado',\n",
    "'bairro_Recife',\n",
    "'bairro_S_Jose',\n",
    "'bairro_San_Martin',\n",
    "'bairro_Sancho',\n",
    "'bairro_Santana',\n",
    "'bairro_Setubal',\n",
    "'bairro_Soledade',\n",
    "'bairro_Sto_Amaro',\n",
    "'bairro_Sto_Antonio',\n",
    "'bairro_Tamarineira',\n",
    "'bairro_Tejipio',\n",
    "'bairro_Torreao',\n",
    "'bairro_Varzea',\n",
    "'bairro_Zumbi',\n",
    "'diferenciais_campo_de_futebol_e_copa',\n",
    "'diferenciais_campo_de_futebol_e_esquina',\n",
    "'diferenciais_campo_de_futebol_e_estacionamento_visitantes',\n",
    "'diferenciais_campo_de_futebol_e_playground',\n",
    "'diferenciais_campo_de_futebol_e_quadra_poliesportiva',\n",
    "'diferenciais_campo_de_futebol_e_salao_de_festas',\n",
    "'diferenciais_children_care',\n",
    "'diferenciais_children_care_e_playground',\n",
    "'diferenciais_churrasqueira',\n",
    "'diferenciais_churrasqueira_e_campo_de_futebol',\n",
    "'diferenciais_churrasqueira_e_copa',\n",
    "'diferenciais_churrasqueira_e_esquina',\n",
    "'diferenciais_churrasqueira_e_estacionamento_visitantes',\n",
    "'diferenciais_churrasqueira_e_frente_para_o_mar',\n",
    "'diferenciais_churrasqueira_e_playground',\n",
    "'diferenciais_churrasqueira_e_sala_de_ginastica',\n",
    "'diferenciais_churrasqueira_e_salao_de_festas',\n",
    "'diferenciais_churrasqueira_e_sauna',\n",
    "'diferenciais_copa',\n",
    "'diferenciais_copa_e_esquina',\n",
    "'diferenciais_copa_e_estacionamento_visitantes',\n",
    "'diferenciais_copa_e_playground',\n",
    "'diferenciais_copa_e_quadra_poliesportiva',\n",
    "'diferenciais_copa_e_sala_de_ginastica',\n",
    "'diferenciais_copa_e_salao_de_festas',\n",
    "'diferenciais_esquina',\n",
    "'diferenciais_esquina_e_estacionamento_visitantes',\n",
    "'diferenciais_esquina_e_playground',\n",
    "'diferenciais_esquina_e_quadra_poliesportiva',\n",
    "'diferenciais_esquina_e_sala_de_ginastica',\n",
    "'diferenciais_esquina_e_salao_de_festas',\n",
    "'diferenciais_estacionamento_visitantes',\n",
    "'diferenciais_estacionamento_visitantes_e_playground',\n",
    "'diferenciais_estacionamento_visitantes_e_sala_de_ginastica',\n",
    "'diferenciais_estacionamento_visitantes_e_salao_de_festas',\n",
    "'diferenciais_frente_para_o_mar',\n",
    "'diferenciais_frente_para_o_mar_e_campo_de_futebol',\n",
    "'diferenciais_frente_para_o_mar_e_copa',\n",
    "'diferenciais_frente_para_o_mar_e_esquina',\n",
    "'diferenciais_frente_para_o_mar_e_playground',\n",
    "'diferenciais_frente_para_o_mar_e_quadra_poliesportiva',\n",
    "'diferenciais_frente_para_o_mar_e_salao_de_festas',\n",
    "'diferenciais_piscina_e_children_care',\n",
    "'diferenciais_piscina_e_esquina',\n",
    "'diferenciais_piscina_e_estacionamento_visitantes',\n",
    "'diferenciais_piscina_e_frente_para_o_mar',\n",
    "'diferenciais_piscina_e_hidromassagem',\n",
    "'diferenciais_piscina_e_quadra_de_squash',\n",
    "'diferenciais_piscina_e_quadra_poliesportiva',\n",
    "'diferenciais_piscina_e_sala_de_ginastica',\n",
    "'diferenciais_piscina_e_salao_de_jogos',\n",
    "'diferenciais_piscina_e_copa',\n",
    "'diferenciais_piscina_e_campo_de_futebol',\n",
    "'diferenciais_piscina',\n",
    "'diferenciais_playground',\n",
    "'diferenciais_playground_e_quadra_poliesportiva',\n",
    "'diferenciais_playground_e_sala_de_ginastica',\n",
    "'diferenciais_playground_e_salao_de_jogos',\n",
    "'diferenciais_quadra_poliesportiva',\n",
    "'diferenciais_quadra_poliesportiva_e_salao_de_festas',\n",
    "'diferenciais_sala_de_ginastica',\n",
    "'diferenciais_sala_de_ginastica_e_salao_de_festas',\n",
    "'diferenciais_sala_de_ginastica_e_salao_de_jogos',\n",
    "'diferenciais_salao_de_festas_e_salao_de_jogos',\n",
    "'diferenciais_salao_de_festas_e_vestiario',\n",
    "'diferenciais_salao_de_jogos',\n",
    "'diferenciais_sauna',\n",
    "'diferenciais_sauna_e_campo_de_futebol',\n",
    "'diferenciais_sauna_e_copa',\n",
    "'diferenciais_sauna_e_esquina',\n",
    "'diferenciais_sauna_e_frente_para_o_mar',\n",
    "'diferenciais_sauna_e_playground',\n",
    "'diferenciais_sauna_e_quadra_poliesportiva',\n",
    "'diferenciais_sauna_e_sala_de_ginastica',\n",
    "'diferenciais_sauna_e_salao_de_festas',\n",
    "'diferenciais_vestiario']\n",
    "\n",
    "for feature in features_classes_dominantes:\n",
    "    dados_treinamento.drop(feature, axis=1, inplace=True)\n",
    "\n",
    "    # Algumas dessas colunas não estão presentes no conjunto de teste.\n",
    "    if feature in dados_teste.columns:\n",
    "        dados_teste.drop(feature, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ha3DZ32_CCzV",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 06 - Remoção de Features que Estavam Somente no Conjunto de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZLXE1tmCE7U"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "#  Remoção de features que estavam somente no conjunto de teste\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "features_somente_dados_teste = [\n",
    "'bairro_Beberibe',\n",
    "'bairro_Fundao',\n",
    "'bairro_Ibura',\n",
    "'diferenciais_campo_de_futebol_e_sala_de_ginastica',\n",
    "'diferenciais_churrasqueira_e_children_care',\n",
    "'diferenciais_copa_e_hidromassagem',\n",
    "'diferenciais_estacionamento_visitantes_e_hidromassagem',\n",
    "'diferenciais_estacionamento_visitantes_e_salao_de_jogos',\n",
    "'diferenciais_frente_para_o_mar_e_children_care',\n",
    "'diferenciais_frente_para_o_mar_e_hidromassagem',\n",
    "'diferenciais_hidromassagem_e_salao_de_festas']\n",
    "\n",
    "dados_teste.drop(features_somente_dados_teste, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzBn62ltvGAG",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 07 - Exibição dos Coeficientes de Pearson de Cada Atributo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yDBqcpNvHYu"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Exibindo os coeficientes de Pearson de cada atributo (entre o mesmo e o alvo)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Coeficiente de Pearson-----\\n\")\n",
    "for coluna in dados_treinamento.columns:\n",
    "    coef_pearsonr = pearsonr(dados_treinamento[coluna], dados_treinamento['inadimplente'])[0]\n",
    "    p_value = pearsonr(dados_treinamento[coluna], dados_treinamento['inadimplente'])[1]\n",
    "    print(f'{coluna}: {coef_pearsonr:.3f}, p-value: {p_value:.3f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "td2qL55nvn96",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 08 - Remoção de Features que Possuíam Um Coeficiente de Pearson Menor que 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dhR3xhkcv0Xp"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Remoção de features que possuíam um coeficiente de Pearson menor que 0.01\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "drop_list_pearson = ['area_extra', 'estacionamento', 'piscina', 'quadra', 's_festas', 'sauna', 'vista_mar', 'tipo_Apartamento',\n",
    "                'tipo_Casa', 'bairro_Boa_Viagem', 'bairro_Casa_Amarela', 'bairro_Encruzilhada', 'bairro_Espinheiro',\n",
    "                'bairro_Gracas', 'bairro_Madalena', 'bairro_Parnamirim', 'bairro_Rosarinho', 'diferenciais_piscina_e_playground',\n",
    "                'diferenciais_piscina_e_salao_de_festas', 'diferenciais_piscina_e_sauna', 'diferenciais_playground_e_salao_de_festas']\n",
    "\n",
    "dados_treinamento.drop(drop_list_pearson, axis=1, inplace=True)\n",
    "dados_teste.drop(drop_list_pearson, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCQshDWywgX1",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 09 - Embaralhamento do Conjunto de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BQcUgqHrwnKB"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Embaralhar o conjunto de dados de treino para garantir que a divisão entre os\n",
    "# dados esteja isenta de qualquer viés de seleção\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "dados_treinamento_embaralhados = dados_treinamento.sample(frac=1, random_state=11012005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T01Qf5x7wt3F",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 10 - Separação do Conjunto de Treinamento em Arrays X e Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Waq1_0Esw1_e"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Separar o conjunto de treinamento em arrays X e Y\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Separando as features do alvo.\n",
    "X = dados_treinamento_embaralhados.iloc[:, :-1].values\n",
    "y = dados_treinamento_embaralhados.iloc[:, -1].values\n",
    "\n",
    "# Conjunto de treino e teste\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.25, random_state=11012005)\n",
    "\n",
    "# Conjunto de teste final\n",
    "X_teste_final = dados_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4Z4IFQHxCHP",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 11 - Aplicação da Escala no X de Treino e de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74apVRP6xF1O"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Aplicação da escala no X de treino e de teste\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Neste caso, os melhores resultados foram encontrados com o StandardScaler()\n",
    "# escala = MinMaxScaler()\n",
    "escala = StandardScaler()\n",
    "\n",
    "escala.fit(X_treino)\n",
    "X_treino_com_escala = escala.transform(X_treino)\n",
    "X_teste_com_escala = escala.transform(X_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olUqmRB2C7pl",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 12 - Criação de uma Função para Calcular o RMSPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9F7w9kfKDBH7"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Criação de uma função para calcular o RMSPE\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    \"Função que retorna o valor do RMSPE.\"\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # Verificar se há zeros em y_true para evitar divisão por zero\n",
    "    if np.any(y_true == 0):\n",
    "        raise ValueError(\"Os valores reais (y_true) não podem conter zeros ao calcular o RMSPE.\")\n",
    "\n",
    "    # Calcular o RMSPE\n",
    "    percentage_errors = ((y_true - y_pred) / y_true) ** 2\n",
    "    rmspe_value = np.sqrt(np.mean(percentage_errors))\n",
    "    return rmspe_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FJ5oB3_0jzW",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 13 - Treinamento do Modelo KNeighborsRegressor\n",
    "\n",
    "- Melhor resultado: n_neighbors = 1, RMSPE = 0.5265, R2 Score = 0.6374"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BI-0AWLo0sUI"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Treinando o modelo KNeighborsClassifier, com k variando entre 1 e 30\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Classificador com KNN-----\\n\")\n",
    "for k in range(1, 31):\n",
    "    # Instanciando o classificador KNN.\n",
    "    classificador_knn = KNeighborsClassifier(n_neighbors=k, weights=\"uniform\")\n",
    "    classificador_knn = classificador_knn.fit(X_treino_com_escala, y_treino)\n",
    "\n",
    "    y_resposta_treino = classificador_knn.predict(X_treino_com_escala)\n",
    "    y_resposta_teste = classificador_knn.predict(X_teste_com_escala)\n",
    "\n",
    "    acuracia_treino = accuracy_score(y_treino, y_resposta_treino)\n",
    "    acuracia_teste = accuracy_score(y_teste, y_resposta_teste)\n",
    "\n",
    "    print(f'\\nK = {k}')\n",
    "    print(f'Acurácia Treino: {(acuracia_treino * 100):.4f}%')\n",
    "    print(f'Taxa de Erro Treino: {((1 - acuracia_treino) * 100):.4f}%')\n",
    "    print(f'Acurácia Teste: {(acuracia_teste * 100):.4f}%')\n",
    "    print(f'Taxa de Erro Teste: {((1 - acuracia_teste) * 100):.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ew4KK-CD7i2H",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 14 - Treinando o modelo Regressão Linear\n",
    "\n",
    "- Resultado: RMSPE = 5.5511, R2 Score = -9.0472"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m1xEHOG27nB1"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "#  Treinando o modelo Regressão Linear\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Regressor com Regressão Linear-----\\n\")\n",
    "\n",
    "# Instanciando o regressor Regressão Linear.\n",
    "regressor_regressao_linear = LinearRegression()\n",
    "regressor_regressao_linear = regressor_regressao_linear.fit(X_treino_com_escala, y_treino)\n",
    "\n",
    "# Predições.\n",
    "y_resposta_treino = regressor_regressao_linear.predict(X_treino_com_escala)\n",
    "y_resposta_teste = regressor_regressao_linear.predict(X_teste_com_escala)\n",
    "\n",
    "# Calculando RMSPE e o R2 Score.\n",
    "rmspe_treino = rmspe(y_treino, y_resposta_treino)\n",
    "rmspe_teste = rmspe(y_teste, y_resposta_teste)\n",
    "r2_score_teste = r2_score(y_teste, y_resposta_teste)\n",
    "\n",
    "print(f'RMSPE Treino: {rmspe_treino:.4f}')\n",
    "print(f'R2 Score Treino: {r2_score_treino:.4f}')\n",
    "print(f'RMSPE Teste: {rmspe_teste:.4f}')\n",
    "print(f'R2 Score Teste: {r2_score_teste:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owLuUWJW9b-2",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 15 - Treinando o modelo Regressão Polinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xNhdDsE9pZ1"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Treinando o modelo Regressão Polinomial\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Regressor com Regressão Polinomial-----\\n\")\n",
    "\n",
    "# Para este laço, o melhor resultado foi em grau = 1 com RMSPE = 5.5511 e R2 Score = -9.0472\n",
    "# for grau in range(1, 11):\n",
    "\n",
    "# Por fim, escolhemos grau = 1.\n",
    "grau = 1\n",
    "\n",
    "# Instanciando o metodo PolynomialFeatures.\n",
    "polynomial_features = PolynomialFeatures(degree=grau)\n",
    "polynomial_features = polynomial_features.fit(X_treino)\n",
    "X_treino_poly = polynomial_features.transform(X_treino_com_escala)\n",
    "X_teste_poly = polynomial_features.transform(X_teste_com_escala)\n",
    "\n",
    "# Instanciando o regressor Regressão Linear.\n",
    "regressor_regressao_linear = LinearRegression()\n",
    "regressor_regressao_linear = regressor_regressao_linear.fit(X_treino_poly, y_treino)\n",
    "\n",
    "# Predições.\n",
    "y_resposta_treino = regressor_regressao_linear.predict(X_treino_poly)\n",
    "y_resposta_teste = regressor_regressao_linear.predict(X_teste_poly)\n",
    "\n",
    "# Calculando RMSPE e o R2 Score.\n",
    "rmspe_treino = rmspe(y_treino, y_resposta_treino)\n",
    "rmspe_teste = rmspe(y_teste, y_resposta_teste)\n",
    "r2_score_treino = r2_score(y_treino, y_resposta_treino)\n",
    "r2_score_teste = r2_score(y_teste, y_resposta_teste)\n",
    "\n",
    "print(f'\\nGrau = {grau}')\n",
    "print(f'RMSPE Treino: {rmspe_treino:.4f}')\n",
    "print(f'R2 Score Treino: {r2_score_treino:.4f}')\n",
    "print(f'RMSPE Teste: {rmspe_teste:.4f}')\n",
    "print(f'R2 Score Teste: {r2_score_teste:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2P9Aqe9_f2X",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 16 - Treinando o modelo Regressão Polinomial com regularização Ridge (L2)\n",
    "\n",
    "- Melhor resultado: degree = 2, alpha = 5000000000, RMSPE = 1.6604, R2 Score = -0.1581"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocLB3Uvw_j73"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Treinando o modelo Regressão Polinomial com regularização Ridge (L2)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n\\t-----Regressor com Regressão Polinomial com regularização Ridge (L2)-----\\n\")\n",
    "print('   ALPHA\\t     RMSPE Treino      R2 Score       RMSPE Teste      R2 Score Teste')\n",
    "print(' ---------- \\t -----------    ------------    -------------    ---------------')\n",
    "\n",
    "# Para este laço, o melhor resultado foi em a = 10000000000 com RMSPE = 1.6604 e R2 Score = -0.1581\n",
    "# for a in [0.001, 0.010, 0.100, 1.000, 10.00, 100.0, 1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000, 10000000000, 100000000000]:\n",
    "\n",
    "# Para este laço, o melhor resultado foi em a = 5000000000 com RMSPE = 1.6604  e R2 Score = -0.1581\n",
    "# for a in [100000000, 200000000, 300000000, 400000000, 500000000, 600000000, 700000000, 800000000, 900000000, 900000000, 1000000000,\n",
    "          # 1500000000, 2000000000, 3000000000, 4000000000, 5000000000, 6000000000, 7000000000, 8000000000, 9000000000, 10000000000]:\n",
    "\n",
    "# Por fim, escolhemos a = 5000000000.\n",
    "a = 5000000000\n",
    "\n",
    "# Instanciando o metodo PolynomialFeatures.\n",
    "polynomial_features = PolynomialFeatures(degree=2)\n",
    "polynomial_features = polynomial_features.fit(X_treino)\n",
    "X_treino_poly = polynomial_features.transform(X_treino_com_escala)\n",
    "X_teste_poly = polynomial_features.transform(X_teste_com_escala)\n",
    "\n",
    "# Instanciando a regularização Ridge (L2).\n",
    "regularizacao_ridge = Ridge(alpha=a)\n",
    "regularizacao_ridge = regularizacao_ridge.fit(X_treino_poly, y_treino)\n",
    "\n",
    "# Predições.\n",
    "y_resposta_treino = regularizacao_ridge.predict(X_treino_poly)\n",
    "y_resposta_teste = regularizacao_ridge.predict(X_teste_poly)\n",
    "\n",
    "# Calculando RMSPE e o R2 Score.\n",
    "rmspe_treino = rmspe(y_treino, y_resposta_treino)\n",
    "rmspe_teste = rmspe(y_teste, y_resposta_teste)\n",
    "r2_score_treino = r2_score(y_treino, y_resposta_treino)\n",
    "r2_score_teste = r2_score(y_teste, y_resposta_teste)\n",
    "\n",
    "print(f'  {a} ', f'\\t\\t   {rmspe_treino:.4f} ', f'\\t\\t   {r2_score_treino:.4f} ', f'\\t\\t   {rmspe_teste:.4f}', f'\\t\\t   {r2_score_teste:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ze8yuROgCkr-",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 17 - Treinamento da Submissão Final para o Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PofH2XsyCppH"
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "# Treinando a submissão final para o Kaggle, com o modelo que obteve o melhor\n",
    "# RMSPE e R2 Score (KNN).\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "# Utilizando todos os dados.\n",
    "X_treino_submissao = X\n",
    "X_teste_submissao = X_teste_final\n",
    "y_treino_submissao = y\n",
    "\n",
    "# Colocando em escala.\n",
    "escala = StandardScaler()\n",
    "escala.fit(X_treino_submissao)\n",
    "X_treino_submissao_com_escala = escala.transform(X_treino_submissao)\n",
    "X_teste_submissao_com_escala = escala.transform(X_teste_submissao)\n",
    "\n",
    "# Aplicando o modelo\n",
    "k = 1\n",
    "regressor_knn = KNeighborsRegressor(n_neighbors=k, weights=\"uniform\")\n",
    "regressor_knn = regressor_knn.fit(X_treino_submissao_com_escala, y_treino_submissao)\n",
    "y_resposta_teste_submissao = regressor_knn.predict(X_teste_submissao_com_escala)\n",
    "\n",
    "# Criando o DataFrame de submissão.\n",
    "submissao_final_kaggle = pd.DataFrame({\n",
    "    'Id': ids_dados_teste,\n",
    "    'preco': y_resposta_teste_submissao\n",
    "})\n",
    "\n",
    "# Salvando em CSV\n",
    "submissao_final_kaggle.to_csv('submissao_final_kaggle.csv', index=False)\n",
    "print(\"Arquivo salvo como 'submissao_final_kaggle.csv'\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
